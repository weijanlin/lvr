# -*- coding: utf-8 -*-
"""
åˆ†æå­æª”æ¡ˆçµæ§‹
æª¢æŸ¥_build.csv, _land.csv, _park.csvçš„æ¬„ä½
"""

import pandas as pd
import os
import glob
from typing import Dict, List, Set

def analyze_subfile_structure():
    """åˆ†æå­æª”æ¡ˆçµæ§‹"""
    print("ğŸ” åˆ†æå­æª”æ¡ˆçµæ§‹")
    print("=" * 80)
    
    # åˆ†æ113Q1è³‡æ–™å¤¾ä¸­çš„å­æª”æ¡ˆ
    folder_path = "113Q1"
    
    if not os.path.exists(folder_path):
        print(f"âŒ è³‡æ–™å¤¾ä¸å­˜åœ¨: {folder_path}")
        return
    
    # åˆ†æä¸åŒé¡å‹çš„å­æª”æ¡ˆ
    subfile_types = {
        'å»ºç‰©æª”æ¡ˆ': '_build.csv',
        'åœŸåœ°æª”æ¡ˆ': '_land.csv', 
        'åœè»Šå ´æª”æ¡ˆ': '_park.csv'
    }
    
    results = {}
    
    for subfile_type, suffix in subfile_types.items():
        print(f"\nğŸ“Š åˆ†æ {subfile_type} ({suffix})")
        print("-" * 60)
        
        # å°‹æ‰¾åŒ¹é…çš„æª”æ¡ˆ
        pattern = os.path.join(folder_path, f"*{suffix}")
        files = glob.glob(pattern)
        
        if not files:
            print(f"âš ï¸ æœªæ‰¾åˆ° {subfile_type} æª”æ¡ˆ")
            continue
        
        # åˆ†æç¬¬ä¸€å€‹æ‰¾åˆ°çš„æª”æ¡ˆ
        sample_file = files[0]
        print(f"ğŸ“ åˆ†ææª”æ¡ˆ: {sample_file}")
        
        try:
            # è®€å–CSVæª”æ¡ˆ
            df = pd.read_csv(sample_file, encoding='utf-8')
            
            # åŸºæœ¬è³‡è¨Š
            print(f"   è¡Œæ•¸: {len(df)}")
            print(f"   æ¬„ä½æ•¸: {len(df.columns)}")
            
            # æ¬„ä½åˆ—è¡¨
            columns = list(df.columns)
            print(f"   æ¬„ä½åˆ—è¡¨:")
            for i, col in enumerate(columns, 1):
                print(f"     {i:2d}. {col}")
            
            # å„²å­˜çµæœ
            results[subfile_type] = {
                'file': sample_file,
                'rows': len(df),
                'columns': len(df.columns),
                'column_list': columns
            }
            
            # é¡¯ç¤ºå‰å¹¾è¡Œè³‡æ–™æ¨£æœ¬
            print(f"   è³‡æ–™æ¨£æœ¬ (å‰3è¡Œ):")
            for i in range(min(3, len(df))):
                print(f"     è¡Œ {i+1}: {dict(df.iloc[i].head(5))}")
            
        except Exception as e:
            print(f"âŒ è®€å–æª”æ¡ˆå¤±æ•—: {str(e)}")
            results[subfile_type] = {
                'file': sample_file,
                'error': str(e)
            }
    
    # åˆ†æä¸åŒè³‡æ–™é¡å‹çš„å­æª”æ¡ˆå·®ç•°
    print(f"\nğŸ” ä¸åŒè³‡æ–™é¡å‹çš„å­æª”æ¡ˆåˆ†æ")
    print("=" * 80)
    
    # åˆ†æä¸­å¤å±‹ã€é å”®å±‹ã€ç§Ÿå±‹çš„å­æª”æ¡ˆ
    data_types = {
        'ä¸­å¤å±‹': '_a',
        'é å”®å±‹': '_b',
        'ç§Ÿå±‹': '_c'
    }
    
    for data_type, prefix in data_types.items():
        print(f"\nğŸ“Š {data_type} å­æª”æ¡ˆåˆ†æ:")
        print("-" * 60)
        
        for subfile_type, suffix in subfile_types.items():
            pattern = os.path.join(folder_path, f"*{prefix}{suffix}")
            files = glob.glob(pattern)
            
            if files:
                sample_file = files[0]
                print(f"\nğŸ”¸ {subfile_type}:")
                print(f"   æª”æ¡ˆ: {os.path.basename(sample_file)}")
                
                try:
                    df = pd.read_csv(sample_file, encoding='utf-8')
                    print(f"   è¡Œæ•¸: {len(df)}")
                    print(f"   æ¬„ä½æ•¸: {len(df.columns)}")
                    print(f"   æ¬„ä½: {', '.join(df.columns)}")
                except Exception as e:
                    print(f"   âŒ è®€å–å¤±æ•—: {str(e)}")
            else:
                print(f"\nğŸ”¸ {subfile_type}: æœªæ‰¾åˆ°æª”æ¡ˆ")
    
    # æ¯”è¼ƒä¸åŒè³‡æ–™é¡å‹çš„å­æª”æ¡ˆæ¬„ä½å·®ç•°
    print(f"\nğŸ” å­æª”æ¡ˆæ¬„ä½å·®ç•°åˆ†æ")
    print("=" * 80)
    
    # æ”¶é›†æ‰€æœ‰å­æª”æ¡ˆçš„æ¬„ä½
    all_columns = {}
    
    for data_type, prefix in data_types.items():
        all_columns[data_type] = {}
        
        for subfile_type, suffix in subfile_types.items():
            pattern = os.path.join(folder_path, f"*{prefix}{suffix}")
            files = glob.glob(pattern)
            
            if files:
                try:
                    df = pd.read_csv(files[0], encoding='utf-8')
                    all_columns[data_type][subfile_type] = set(df.columns)
                except:
                    all_columns[data_type][subfile_type] = set()
            else:
                all_columns[data_type][subfile_type] = set()
    
    # åˆ†ææ¬„ä½å·®ç•°
    for subfile_type in subfile_types.keys():
        print(f"\nğŸ“‹ {subfile_type} æ¬„ä½æ¯”è¼ƒ:")
        print("-" * 40)
        
        # æ”¶é›†æ‰€æœ‰è³‡æ–™é¡å‹çš„æ¬„ä½
        columns_by_type = {}
        for data_type in data_types.keys():
            if subfile_type in all_columns[data_type]:
                columns_by_type[data_type] = all_columns[data_type][subfile_type]
        
        if len(columns_by_type) >= 2:
            # æ‰¾å‡ºå…±åŒæ¬„ä½
            common_columns = set.intersection(*columns_by_type.values())
            print(f"âœ… å…±åŒæ¬„ä½ ({len(common_columns)} å€‹):")
            for col in sorted(common_columns):
                print(f"   - {col}")
            
            # æ‰¾å‡ºå„é¡å‹ç¨æœ‰çš„æ¬„ä½
            for data_type, columns in columns_by_type.items():
                unique_columns = columns - common_columns
                if unique_columns:
                    print(f"\nğŸ”¸ {data_type} ç¨æœ‰æ¬„ä½ ({len(unique_columns)} å€‹):")
                    for col in sorted(unique_columns):
                        print(f"   - {col}")
    
    # ç”Ÿæˆå­æª”æ¡ˆè³‡æ–™è¡¨çµæ§‹å»ºè­°
    print(f"\nğŸ’¡ å­æª”æ¡ˆè³‡æ–™è¡¨çµæ§‹å»ºè­°")
    print("=" * 80)
    
    for subfile_type, suffix in subfile_types.items():
        if subfile_type in results and 'column_list' in results[subfile_type]:
            print(f"\nğŸ“Š {subfile_type} è³‡æ–™è¡¨çµæ§‹:")
            print(f"CREATE TABLE {subfile_type.lower().replace('æª”æ¡ˆ', '')}_data (")
            
            columns = results[subfile_type]['column_list']
            for i, col in enumerate(columns):
                # æ ¹æ“šæ¬„ä½åç¨±æ¨æ¸¬è³‡æ–™é¡å‹
                if any(keyword in col for keyword in ['é¢ç©', 'åƒ¹æ ¼', 'ç¸½åƒ¹', 'å–®åƒ¹', 'é‡‘é¡', 'æŒåˆ†']):
                    data_type = "DECIMAL(15,2)"
                elif any(keyword in col for keyword in ['æ•¸é‡', 'ç­†æ•¸', 'å±¤æ•¸', 'æˆ¿', 'å»³', 'è¡›', 'å±‹é½¡']):
                    data_type = "INT"
                elif any(keyword in col for keyword in ['å¹´æœˆæ—¥', 'æ—¥æœŸ']):
                    data_type = "NVARCHAR(20)"
                else:
                    data_type = "NVARCHAR(200)"
                
                comma = "," if i < len(columns) - 1 else ""
                print(f"    {col} {data_type}{comma}")
            
            print(");")
    
    return results

def analyze_specific_subfiles():
    """åˆ†æç‰¹å®šçš„å­æª”æ¡ˆ"""
    print(f"\nğŸ” åˆ†æç‰¹å®šå­æª”æ¡ˆ")
    print("=" * 80)
    
    # åˆ†æç‰¹å®šæª”æ¡ˆ
    specific_files = [
        "113Q1/a_lvr_land_a_build.csv",  # ä¸­å¤å±‹å»ºç‰©
        "113Q1/a_lvr_land_a_land.csv",   # ä¸­å¤å±‹åœŸåœ°
        "113Q1/a_lvr_land_a_park.csv",   # ä¸­å¤å±‹åœè»Šå ´
        "113Q1/a_lvr_land_b_land.csv",   # é å”®å±‹åœŸåœ°
        "113Q1/a_lvr_land_b_park.csv",   # é å”®å±‹åœè»Šå ´
        "113Q1/a_lvr_land_c_build.csv",  # ç§Ÿå±‹å»ºç‰©
        "113Q1/a_lvr_land_c_land.csv",   # ç§Ÿå±‹åœŸåœ°
        "113Q1/a_lvr_land_c_park.csv",   # ç§Ÿå±‹åœè»Šå ´
    ]
    
    for file_path in specific_files:
        if os.path.exists(file_path):
            print(f"\nğŸ“„ åˆ†ææª”æ¡ˆ: {os.path.basename(file_path)}")
            print("-" * 60)
            
            try:
                df = pd.read_csv(file_path, encoding='utf-8')
                print(f"   è¡Œæ•¸: {len(df)}")
                print(f"   æ¬„ä½æ•¸: {len(df.columns)}")
                print(f"   æ¬„ä½: {', '.join(df.columns)}")
                
                # é¡¯ç¤ºè³‡æ–™æ¨£æœ¬
                if len(df) > 0:
                    print(f"   æ¨£æœ¬è³‡æ–™:")
                    for i in range(min(2, len(df))):
                        sample_data = dict(df.iloc[i])
                        # åªé¡¯ç¤ºå‰5å€‹æ¬„ä½
                        sample_keys = list(sample_data.keys())[:5]
                        sample_dict = {k: sample_data[k] for k in sample_keys}
                        print(f"     è¡Œ {i+1}: {sample_dict}")
                
            except Exception as e:
                print(f"   âŒ è®€å–å¤±æ•—: {str(e)}")
        else:
            print(f"\nâŒ æª”æ¡ˆä¸å­˜åœ¨: {file_path}")

def save_analysis_results(results: Dict):
    """å„²å­˜åˆ†æçµæœåˆ°æª”æ¡ˆ"""
    try:
        with open('subfile_structure_analysis.txt', 'w', encoding='utf-8') as f:
            f.write("å­æª”æ¡ˆçµæ§‹åˆ†æçµæœ\n")
            f.write("=" * 50 + "\n\n")
            
            for subfile_type, data in results.items():
                f.write(f"{subfile_type}:\n")
                f.write(f"  æª”æ¡ˆ: {data.get('file', 'N/A')}\n")
                f.write(f"  è¡Œæ•¸: {data.get('rows', 'N/A')}\n")
                f.write(f"  æ¬„ä½æ•¸: {data.get('columns', 'N/A')}\n")
                
                if 'column_list' in data:
                    f.write("  æ¬„ä½åˆ—è¡¨:\n")
                    for col in data['column_list']:
                        f.write(f"    - {col}\n")
                
                if 'error' in data:
                    f.write(f"  éŒ¯èª¤: {data['error']}\n")
                
                f.write("\n")
        
        print(f"\nğŸ’¾ åˆ†æçµæœå·²å„²å­˜åˆ°: subfile_structure_analysis.txt")
        
    except Exception as e:
        print(f"âŒ å„²å­˜åˆ†æçµæœå¤±æ•—: {str(e)}")

if __name__ == "__main__":
    results = analyze_subfile_structure()
    analyze_specific_subfiles()
    save_analysis_results(results)




